{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building regression models for arr_delay and dep_delay\n",
    "Identifying the most suitable model out of different modeling approaches including, linear regression, nonlinear regression, random forest regression, boosted tree regression & support verctor regression. For each model approach different hyperparameters will be analysed supported by k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "\n",
    "data_path = '../data/processed/'\n",
    "df = pd.read_pickle(os.path.join(data_path, 'final.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flt_ac_reg</th>\n",
       "      <th>ground_delay</th>\n",
       "      <th>flt_ac_type</th>\n",
       "      <th>flt_tt</th>\n",
       "      <th>flt_sched_tt</th>\n",
       "      <th>block_delay</th>\n",
       "      <th>routing</th>\n",
       "      <th>sched_gt</th>\n",
       "      <th>act_gt</th>\n",
       "      <th>cp_count</th>\n",
       "      <th>ca_count</th>\n",
       "      <th>cc_cp_ca</th>\n",
       "      <th>cc_count</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day_dep</th>\n",
       "      <th>hour_of_day_arr</th>\n",
       "      <th>cc_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ECLBAX</td>\n",
       "      <td>25.0</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>New Jessica_East Carmen</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>ECLBAX</td>\n",
       "      <td>15.0</td>\n",
       "      <td>320</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>East Carmen_South Nathaniel</td>\n",
       "      <td>75.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>both</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>ECLBAX</td>\n",
       "      <td>51.0</td>\n",
       "      <td>320</td>\n",
       "      <td>68.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>South Nathaniel_East Carmen</td>\n",
       "      <td>80.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>ECLBAX</td>\n",
       "      <td>43.0</td>\n",
       "      <td>320</td>\n",
       "      <td>64.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>East Carmen_Joneshaven</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>both</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>ECLBAX</td>\n",
       "      <td>20.0</td>\n",
       "      <td>320</td>\n",
       "      <td>73.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>East Carmen_Joneshaven</td>\n",
       "      <td>45.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    flt_ac_reg  ground_delay flt_ac_type  flt_tt  flt_sched_tt  block_delay  \\\n",
       "9       ECLBAX          25.0         320     0.0           0.0         16.0   \n",
       "117     ECLBAX          15.0         320    60.0          60.0          6.0   \n",
       "194     ECLBAX          51.0         320    68.0          75.0         37.0   \n",
       "268     ECLBAX          43.0         320    64.0          70.0         32.0   \n",
       "416     ECLBAX          20.0         320    73.0          45.0         22.0   \n",
       "\n",
       "                         routing  sched_gt  act_gt cp_count ca_count cc_cp_ca  \\\n",
       "9        New Jessica_East Carmen      95.0    94.0        2        4     none   \n",
       "117  East Carmen_South Nathaniel      75.0   120.0        2        4     both   \n",
       "194  South Nathaniel_East Carmen      80.0    86.0        2        4     none   \n",
       "268       East Carmen_Joneshaven      50.0    32.0        2        4     both   \n",
       "416       East Carmen_Joneshaven      45.0    38.0        2        4     none   \n",
       "\n",
       "    cc_count day_of_week hour_of_day_dep hour_of_day_arr cc_types  \n",
       "9          0           5               3               6        0  \n",
       "117        6           5               8              10        3  \n",
       "194        0           5              11              14        1  \n",
       "268        6           5              15              17        3  \n",
       "416        0           6               6               8        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7975, 389)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode all catgorical variables\n",
    "df_one_hot = pd.get_dummies(df, drop_first=True)\n",
    "df_one_hot.dropna(axis=0, how='any', inplace=True)\n",
    "df_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train/test splits for both intermediate models\n",
    "X_train_arr, X_test_arr, y_train_arr, y_test_arr = train_test_split(df_one_hot.drop(['arr_delay'], axis=1), df_one_hot['arr_delay'], test_size=0.33, random_state=42)\n",
    "X_train_dep, X_test_dep, y_train_dep, y_test_dep = train_test_split(df_one_hot.drop(['dep_delay'], axis=1), df_one_hot['dep_delay'], test_size=0.33, random_state=42)\n",
    "\n",
    "# Create dataframe to save model evaluation parameters\n",
    "eval = pd.DataFrame(columns= ['Group', 'Model', 'Parameters', 'R^2 test', 'RMSE test', 'R^2 train', 'RMSE train'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>R^2 test</th>\n",
       "      <th>RMSE test</th>\n",
       "      <th>R^2 train</th>\n",
       "      <th>RMSE train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Block</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.545989e+14</td>\n",
       "      <td>3.071859e+08</td>\n",
       "      <td>0.919</td>\n",
       "      <td>5.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ground</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.108956e+16</td>\n",
       "      <td>3.187293e+09</td>\n",
       "      <td>0.913</td>\n",
       "      <td>5.412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Group   Model  Parameters      R^2 test     RMSE test  R^2 train  \\\n",
       "0   Block  Linear         NaN -2.545989e+14  3.071859e+08      0.919   \n",
       "1  Ground  Linear         NaN -3.108956e+16  3.187293e+09      0.913   \n",
       "\n",
       "   RMSE train  \n",
       "0       5.574  \n",
       "1       5.412  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a linear regression model for arr and dep delay\n",
    "lr_arr = LinearRegression(fit_intercept=True)\n",
    "lr_dep = LinearRegression(fit_intercept=True)\n",
    "\n",
    "# Fit models to training data\n",
    "lr_arr.fit(X_train_arr, y_train_arr)\n",
    "lr_dep.fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Predict values for train and test data\n",
    "lr_pred_arr_train = lr_arr.predict(X_train_arr)\n",
    "lr_pred_dep_train = lr_dep.predict(X_train_dep)\n",
    "\n",
    "lr_pred_arr_test = lr_arr.predict(X_test_arr)\n",
    "lr_pred_dep_test = lr_dep.predict(X_test_dep)\n",
    "\n",
    "# Save r^2 and RMSE for both models in dataframe for later comparison\n",
    "\n",
    "eval = eval.append({\n",
    "    'Group': 'arr',\n",
    "    'Model': 'Linear',\n",
    "    'R^2 test': r2_score(y_test_arr, lr_pred_arr_test),\n",
    "    'RMSE test': mean_squared_error(y_test_arr, lr_pred_arr_test, squared=False),\n",
    "    'R^2 train': r2_score(y_train_arr, lr_pred_arr_train),\n",
    "    'RMSE train': mean_squared_error(y_train_arr, lr_pred_arr_train, squared=False)\n",
    "    }, ignore_index=True)\n",
    " \n",
    "eval = eval.append({\n",
    "    'Group': 'dep',\n",
    "    'Model': 'Linear',\n",
    "    'R^2 test': r2_score(y_test_dep, lr_pred_dep_test),\n",
    "    'RMSE test': mean_squared_error(y_test_dep, lr_pred_dep_test, squared=False),\n",
    "    'R^2 train': r2_score(y_train_dep, lr_pred_dep_train),\n",
    "    'RMSE train': mean_squared_error(y_train_dep, lr_pred_dep_train, squared=False)\n",
    "    }, ignore_index=True)\n",
    "\n",
    "eval.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'alpha': 2}\n",
      "{'alpha': 2}\n"
     ]
    }
   ],
   "source": [
    "# Range of regularization parameter alpha\n",
    "alpha = [int(x) for x in np.linspace(1, 3, 20)]\n",
    "\n",
    "# Create random grid\n",
    "param_grid = {'alpha': alpha}\n",
    "\n",
    "# Create a ridge regression model for arr and dep delay\n",
    "rid_arr = Ridge(fit_intercept=True)\n",
    "rid_dep = Ridge(fit_intercept=True)\n",
    "\n",
    "# Initiate the grid search models\n",
    "grid_arr = GridSearchCV(estimator=rid_arr, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_dep = GridSearchCV(estimator=rid_dep, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search models\n",
    "grid_arr.fit(X_train_arr, y_train_arr)\n",
    "grid_dep.fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Print best parameters for the models\n",
    "print(grid_arr.best_params_)\n",
    "print(grid_dep.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>R^2 test</th>\n",
       "      <th>RMSE test</th>\n",
       "      <th>R^2 train</th>\n",
       "      <th>RMSE train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Block</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.545989e+14</td>\n",
       "      <td>3.071859e+08</td>\n",
       "      <td>0.919</td>\n",
       "      <td>5.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ground</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.108956e+16</td>\n",
       "      <td>3.187293e+09</td>\n",
       "      <td>0.913</td>\n",
       "      <td>5.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Block</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.080000e-01</td>\n",
       "      <td>5.847000e+00</td>\n",
       "      <td>0.917</td>\n",
       "      <td>5.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ground</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>5.712000e+00</td>\n",
       "      <td>0.911</td>\n",
       "      <td>5.459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Group   Model  Parameters      R^2 test     RMSE test  R^2 train  \\\n",
       "0   Block  Linear         NaN -2.545989e+14  3.071859e+08      0.919   \n",
       "1  Ground  Linear         NaN -3.108956e+16  3.187293e+09      0.913   \n",
       "2   Block   Ridge         NaN  9.080000e-01  5.847000e+00      0.917   \n",
       "3  Ground   Ridge         NaN  9.000000e-01  5.712000e+00      0.911   \n",
       "\n",
       "   RMSE train  \n",
       "0       5.574  \n",
       "1       5.412  \n",
       "2       5.626  \n",
       "3       5.459  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ridge regression models with best alpha values\n",
    "rid_arr = Ridge(alpha=2, fit_intercept=True)\n",
    "rid_dep = Ridge(alpha=2, fit_intercept=True)\n",
    "\n",
    "# Fit models to training data\n",
    "rid_arr.fit(X_train_arr, y_train_arr)\n",
    "rid_dep.fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Predict values for train and test data\n",
    "rid_pred_arr_train = rid_arr.predict(X_train_arr)\n",
    "rid_pred_dep_train = rid_dep.predict(X_train_dep)\n",
    "\n",
    "rid_pred_arr_test = rid_arr.predict(X_test_arr)\n",
    "rid_pred_dep_test = rid_dep.predict(X_test_dep)\n",
    "\n",
    "# Save r^2 and RMSE for both models in dataframe for later comparison\n",
    "eval = eval.append({\n",
    "    'Group': 'arr',\n",
    "    'Model': 'Ridge',\n",
    "    'R^2 test': r2_score(y_test_arr, rid_pred_arr_test),\n",
    "    'RMSE test': mean_squared_error(y_test_arr, rid_pred_arr_test, squared=False),\n",
    "    'R^2 train': r2_score(y_train_arr, rid_pred_arr_train),\n",
    "    'RMSE train': mean_squared_error(y_train_arr, rid_pred_arr_train, squared=False)\n",
    "    }, ignore_index=True)\n",
    " \n",
    "eval = eval.append({\n",
    "    'Group': 'dep',\n",
    "    'Model': 'Ridge',\n",
    "    'R^2 test': r2_score(y_test_dep, rid_pred_dep_test),\n",
    "    'RMSE test': mean_squared_error(y_test_dep, rid_pred_dep_test, squared=False),\n",
    "    'R^2 train': r2_score(y_train_dep, rid_pred_dep_train),\n",
    "    'RMSE train': mean_squared_error(y_train_dep, rid_pred_dep_train, squared=False)\n",
    "    }, ignore_index=True)\n",
    "\n",
    "eval.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "{'alpha': 0}\n",
      "{'alpha': 0}\n"
     ]
    }
   ],
   "source": [
    "# Range of regularization parameter alpha\n",
    "alpha = [int(x) for x in np.linspace(0, 10, 11)]\n",
    "\n",
    "# Create random grid\n",
    "param_grid = {'alpha': alpha}\n",
    "\n",
    "# Create a lasso regression model for arr and dep delay\n",
    "las_arr = Lasso(fit_intercept=True)\n",
    "las_dep = Lasso(fit_intercept=True)\n",
    "\n",
    "# Initiate the grid search models\n",
    "grid_arr = GridSearchCV(estimator=las_arr, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_dep = GridSearchCV(estimator=las_dep, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search models\n",
    "grid_arr.fit(X_train_arr, y_train_arr)\n",
    "grid_dep.fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Print best parameters for the models\n",
    "print(grid_arr.best_params_)\n",
    "print(grid_dep.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>R^2 test</th>\n",
       "      <th>RMSE test</th>\n",
       "      <th>R^2 train</th>\n",
       "      <th>RMSE train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Block</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.545989e+14</td>\n",
       "      <td>3.071859e+08</td>\n",
       "      <td>0.919</td>\n",
       "      <td>5.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ground</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.108956e+16</td>\n",
       "      <td>3.187293e+09</td>\n",
       "      <td>0.913</td>\n",
       "      <td>5.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Block</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.080000e-01</td>\n",
       "      <td>5.847000e+00</td>\n",
       "      <td>0.917</td>\n",
       "      <td>5.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ground</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>5.712000e+00</td>\n",
       "      <td>0.911</td>\n",
       "      <td>5.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Block</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.060000e-01</td>\n",
       "      <td>5.893000e+00</td>\n",
       "      <td>0.918</td>\n",
       "      <td>5.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ground</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.980000e-01</td>\n",
       "      <td>5.784000e+00</td>\n",
       "      <td>0.913</td>\n",
       "      <td>5.413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Group   Model  Parameters      R^2 test     RMSE test  R^2 train  \\\n",
       "0   Block  Linear         NaN -2.545989e+14  3.071859e+08      0.919   \n",
       "1  Ground  Linear         NaN -3.108956e+16  3.187293e+09      0.913   \n",
       "2   Block   Ridge         NaN  9.080000e-01  5.847000e+00      0.917   \n",
       "3  Ground   Ridge         NaN  9.000000e-01  5.712000e+00      0.911   \n",
       "4   Block   Lasso         NaN  9.060000e-01  5.893000e+00      0.918   \n",
       "5  Ground   Lasso         NaN  8.980000e-01  5.784000e+00      0.913   \n",
       "\n",
       "   RMSE train  \n",
       "0       5.574  \n",
       "1       5.412  \n",
       "2       5.626  \n",
       "3       5.459  \n",
       "4       5.576  \n",
       "5       5.413  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lasso regression models with best alpha values\n",
    "las_arr = Lasso(alpha=0, fit_intercept=True)\n",
    "las_dep = Lasso(alpha=0, fit_intercept=True)\n",
    "\n",
    "# Fit models to training data\n",
    "las_arr.fit(X_train_arr, y_train_arr)\n",
    "las_dep.fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Predict values for train and test data\n",
    "las_pred_arr_train = las_arr.predict(X_train_arr)\n",
    "las_pred_dep_train = las_dep.predict(X_train_dep)\n",
    "\n",
    "las_pred_arr_test = las_arr.predict(X_test_arr)\n",
    "las_pred_dep_test = las_dep.predict(X_test_dep)\n",
    "\n",
    "# Save r^2 and RMSE for both models in dataframe for later comparison\n",
    "eval = eval.append({\n",
    "    'Group': 'arr',\n",
    "    'Model': 'Lasso',\n",
    "    'R^2 test': r2_score(y_test_arr, las_pred_arr_test),\n",
    "    'RMSE test': mean_squared_error(y_test_arr, las_pred_arr_test, squared=False),\n",
    "    'R^2 train': r2_score(y_train_arr, las_pred_arr_train),\n",
    "    'RMSE train': mean_squared_error(y_train_arr, las_pred_arr_train, squared=False)\n",
    "    }, ignore_index=True)\n",
    " \n",
    "eval = eval.append({\n",
    "    'Group': 'dep',\n",
    "    'Model': 'Lasso',\n",
    "    'R^2 test': r2_score(y_test_dep, las_pred_dep_test),\n",
    "    'RMSE test': mean_squared_error(y_test_dep, las_pred_dep_test, squared=False),\n",
    "    'R^2 train': r2_score(y_train_dep, las_pred_dep_train),\n",
    "    'RMSE train': mean_squared_error(y_train_dep, las_pred_dep_train, squared=False)\n",
    "    }, ignore_index=True)\n",
    "\n",
    "eval.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huber Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'alpha': 1, 'epsilon': 200}\n",
      "{'alpha': 1, 'epsilon': 200}\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid\n",
    "\n",
    "# Range of epsilon\n",
    "epsilon = [int(x) for x in np.linspace(100, 1000, 10)]\n",
    "\n",
    "# Range of alpha\n",
    "alpha = [int(x) for x in np.linspace(0, 1, 10)]\n",
    "\n",
    "# Create random grid\n",
    "param_grid = {\n",
    "    'epsilon': epsilon,\n",
    "    'alpha': alpha\n",
    "    }\n",
    "\n",
    "# Create a Huber regression model for arr and dep delay\n",
    "hub_arr = HuberRegressor(fit_intercept=True)\n",
    "hub_dep = HuberRegressor(fit_intercept=True)\n",
    "\n",
    "# Initiate the grid search models\n",
    "grid_arr = GridSearchCV(estimator=hub_arr, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_dep = GridSearchCV(estimator=hub_dep, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search models\n",
    "grid_arr.fit(X_train_arr, y_train_arr)\n",
    "grid_dep.fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Print best parameters for the models\n",
    "print(grid_arr.best_params_)\n",
    "print(grid_dep.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>R^2 test</th>\n",
       "      <th>RMSE test</th>\n",
       "      <th>R^2 train</th>\n",
       "      <th>RMSE train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Block</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.545989e+14</td>\n",
       "      <td>3.071859e+08</td>\n",
       "      <td>0.919</td>\n",
       "      <td>5.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ground</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.108956e+16</td>\n",
       "      <td>3.187293e+09</td>\n",
       "      <td>0.913</td>\n",
       "      <td>5.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Block</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.080000e-01</td>\n",
       "      <td>5.847000e+00</td>\n",
       "      <td>0.917</td>\n",
       "      <td>5.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ground</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>5.712000e+00</td>\n",
       "      <td>0.911</td>\n",
       "      <td>5.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Block</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.060000e-01</td>\n",
       "      <td>5.893000e+00</td>\n",
       "      <td>0.918</td>\n",
       "      <td>5.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ground</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.980000e-01</td>\n",
       "      <td>5.784000e+00</td>\n",
       "      <td>0.913</td>\n",
       "      <td>5.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Block</td>\n",
       "      <td>Huber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.920000e-01</td>\n",
       "      <td>6.323000e+00</td>\n",
       "      <td>0.895</td>\n",
       "      <td>6.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ground</td>\n",
       "      <td>Huber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.840000e-01</td>\n",
       "      <td>6.163000e+00</td>\n",
       "      <td>0.885</td>\n",
       "      <td>6.215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Group   Model  Parameters      R^2 test     RMSE test  R^2 train  \\\n",
       "0   Block  Linear         NaN -2.545989e+14  3.071859e+08      0.919   \n",
       "1  Ground  Linear         NaN -3.108956e+16  3.187293e+09      0.913   \n",
       "2   Block   Ridge         NaN  9.080000e-01  5.847000e+00      0.917   \n",
       "3  Ground   Ridge         NaN  9.000000e-01  5.712000e+00      0.911   \n",
       "4   Block   Lasso         NaN  9.060000e-01  5.893000e+00      0.918   \n",
       "5  Ground   Lasso         NaN  8.980000e-01  5.784000e+00      0.913   \n",
       "6   Block   Huber         NaN  8.920000e-01  6.323000e+00      0.895   \n",
       "7  Ground   Huber         NaN  8.840000e-01  6.163000e+00      0.885   \n",
       "\n",
       "   RMSE train  \n",
       "0       5.574  \n",
       "1       5.412  \n",
       "2       5.626  \n",
       "3       5.459  \n",
       "4       5.576  \n",
       "5       5.413  \n",
       "6       6.324  \n",
       "7       6.215  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Huber regression models with best alpha and apsilon values\n",
    "hub_arr = HuberRegressor(alpha=1, epsilon=200, fit_intercept=True)\n",
    "hub_dep = HuberRegressor(alpha=1, epsilon=200, fit_intercept=True)\n",
    "\n",
    "# Fit models to training data\n",
    "hub_arr.fit(X_train_arr, y_train_arr)\n",
    "hub_dep.fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Predict values for train and test data\n",
    "hub_pred_arr_train = hub_arr.predict(X_train_arr)\n",
    "hub_pred_dep_train = hub_dep.predict(X_train_dep)\n",
    "\n",
    "hub_pred_arr_test = hub_arr.predict(X_test_arr)\n",
    "hub_pred_dep_test = hub_dep.predict(X_test_dep)\n",
    "\n",
    "# Save r^2 and RMSE for both models in dataframe for later comparison\n",
    "eval = eval.append({\n",
    "    'Group': 'arr',\n",
    "    'Model': 'Huber',\n",
    "    'R^2 test': round(r2_score(y_test_arr, hub_pred_arr_test), 3),\n",
    "    'RMSE test': round(mean_squared_error(y_test_arr, hub_pred_arr_test, squared=False), 3),\n",
    "    'R^2 train': round(r2_score(y_train_arr, hub_pred_arr_train), 3),\n",
    "    'RMSE train': round(mean_squared_error(y_train_arr, hub_pred_arr_train, squared=False), 3)\n",
    "    }, ignore_index=True)\n",
    " \n",
    "eval = eval.append({\n",
    "    'Group': 'dep',\n",
    "    'Model': 'Huber',\n",
    "    'R^2 test': round(r2_score(y_test_dep, hub_pred_dep_test), 3),\n",
    "    'RMSE test': round(mean_squared_error(y_test_dep, hub_pred_dep_test, squared=False), 3),\n",
    "    'R^2 train': round(r2_score(y_train_dep, hub_pred_dep_train), 3),\n",
    "    'RMSE train': round(mean_squared_error(y_train_dep, hub_pred_dep_train, squared=False), 3)\n",
    "    }, ignore_index=True)\n",
    "\n",
    "eval.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'splitter': 'best', 'min_weight_fraction_leaf': 0.0, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.18, 'max_leaf_nodes': 176, 'max_features': 'auto', 'max_depth': 90, 'criterion': 'friedman_mse', 'ccp_alpha': 0.18}\n",
      "{'splitter': 'random', 'min_weight_fraction_leaf': 0.0, 'min_samples_split': 7, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.12, 'max_leaf_nodes': 160, 'max_features': 'auto', 'max_depth': 92, 'criterion': 'friedman_mse', 'ccp_alpha': 0.14}\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid to sample from during fitting\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "ccp_alpha = [float(x) for x in np.linspace(0, 0.2, num=11)]\n",
    "# Measurement of the quality of a split\n",
    "criterion = ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']\n",
    "# Maximum number of leafs in tree\n",
    "max_depth = [int(x) for x in np.linspace(80, 100, num=11)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# Maximum leaf nodes\n",
    "max_leaf_nodes = [int(x) for x in np.linspace(140, 180, num=11)]\n",
    "# Minimum impurity decrease\n",
    "min_impurity_decrease = [float(x) for x in np.linspace(0.1, 0.3, num=11)]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [int(x) for x in np.linspace(5, 15, num=11)]\n",
    "# Minimum weightes fraction of the sum of total of weights required to be at a leaf node\n",
    "min_weight_fraction_leaf = [float(x) for x in np.linspace(0, 0.1, num=11)]\n",
    "# Strategy used to split at each node.\n",
    "splitter = ['best', 'random']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'ccp_alpha': ccp_alpha,\n",
    "    'criterion': criterion,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'max_leaf_nodes': max_leaf_nodes,\n",
    "    'min_impurity_decrease': min_impurity_decrease,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_weight_fraction_leaf': min_weight_fraction_leaf,\n",
    "    'splitter': splitter\n",
    "    }\n",
    "\n",
    "# Create a decision tree regression model for arr and dep delay\n",
    "dt_arr = DecisionTreeRegressor()\n",
    "dt_dep = DecisionTreeRegressor()\n",
    "\n",
    "# Initiate the grid search models\n",
    "dt_arr_random = RandomizedSearchCV(estimator=dt_arr, param_distributions=random_grid, n_iter=100, cv=5, n_jobs=-1, random_state=42, verbose=1)\n",
    "dt_dep_random = RandomizedSearchCV(estimator=dt_dep, param_distributions=random_grid, n_iter=100, cv=5, n_jobs=-1, random_state=42, verbose=1)\n",
    "\n",
    "# Fit the grid search models\n",
    "dt_arr_random.fit(X_train_arr, y_train_arr)\n",
    "dt_dep_random.fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Print best parameters for the models\n",
    "print(dt_arr_random.best_params_)\n",
    "print(dt_dep_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 33 candidates, totalling 165 fits\n",
      "Fitting 5 folds for each of 33 candidates, totalling 165 fits\n",
      "{'ccp_alpha': 0.1, 'criterion': 'friedman_mse', 'max_depth': 91, 'max_features': 'auto', 'max_leaf_nodes': 166, 'min_impurity_decrease': 0.2, 'min_samples_leaf': 1, 'min_samples_split': 12, 'min_weight_fraction_leaf': 0, 'splitter': 'random'}\n",
      "{'ccp_alpha': 0.1, 'criterion': 'friedman_mse', 'max_depth': 91, 'max_features': 'auto', 'max_leaf_nodes': 166, 'min_impurity_decrease': 0.35, 'min_samples_leaf': 1, 'min_samples_split': 12, 'min_weight_fraction_leaf': 0, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid to sample from during fitting\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "ccp_alpha = [0.1]\n",
    "# Measurement of the quality of a split\n",
    "criterion = ['friedman_mse']\n",
    "# Maximum number of leafs in tree\n",
    "max_depth = [91]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "# Maximum leaf nodes\n",
    "max_leaf_nodes = [166]\n",
    "# Minimum impurity decrease\n",
    "min_impurity_decrease = [float(x) for x in np.linspace(0.2, 0.5, num=11)]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [10, 11, 12]\n",
    "# Minimum weightes fraction of the sum of total of weights required to be at a leaf node\n",
    "min_weight_fraction_leaf = [0]\n",
    "# Strategy used to split at each node.\n",
    "splitter = ['random']\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {\n",
    "    'ccp_alpha': ccp_alpha,\n",
    "    'criterion': criterion,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'max_leaf_nodes': max_leaf_nodes,\n",
    "    'min_impurity_decrease': min_impurity_decrease,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_weight_fraction_leaf': min_weight_fraction_leaf,\n",
    "    'splitter': splitter\n",
    "    }\n",
    "\n",
    "# Create a decision tree regression model for arr and dep delay\n",
    "dt_arr = DecisionTreeRegressor()\n",
    "dt_dep = DecisionTreeRegressor()\n",
    "\n",
    "# Initiate the grid search models\n",
    "dt_arr_grid = GridSearchCV(estimator=dt_arr, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "dt_dep_grid = GridSearchCV(estimator=dt_dep, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search models\n",
    "dt_arr_grid.fit(X_train_arr, y_train_arr)\n",
    "dt_dep_grid.fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Print best parameters for the models\n",
    "print(dt_arr_grid.best_params_)\n",
    "print(dt_dep_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Decision Tree regression models with best parameters\n",
    "dt_arr = HuberRegressor(ccp_alpha=0.1, criterion='friedman_mse', max_depth='', max_features='auto',\n",
    "    max_leaf_nodes='', min_impurity_decrease='', min_samples_leaf=1, min_samples_split)\n",
    "dt_dep = HuberRegressor(alpha=1, epsilon=200, fit_intercept=True)\n",
    "\n",
    "# Fit models to training data\n",
    "dt_arr.fit(X_train_arr, y_train_arr)\n",
    "dt_dep.fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Predict values for train and test data\n",
    "hub_pred_arr_train = dt_arr.predict(X_train_arr)\n",
    "hub_pred_dep_train = dt_dep.predict(X_train_dep)\n",
    "\n",
    "hub_pred_arr_test = dt_arr.predict(X_test_arr)\n",
    "hub_pred_dep_test = dt_dep.predict(X_test_dep)\n",
    "\n",
    "# Save r^2 and RMSE for both models in dataframe for later comparison\n",
    "eval = eval.append({\n",
    "    'Group': 'arr',\n",
    "    'Model': 'Huber',\n",
    "    'R^2 test': round(r2_score(y_test_arr, hub_pred_arr_test), 3),\n",
    "    'RMSE test': round(mean_squared_error(y_test_arr, hub_pred_arr_test, squared=False), 3),\n",
    "    'R^2 train': round(r2_score(y_train_arr, hub_pred_arr_train), 3),\n",
    "    'RMSE train': round(mean_squared_error(y_train_arr, hub_pred_arr_train, squared=False), 3)\n",
    "    }, ignore_index=True)\n",
    " \n",
    "eval = eval.append({\n",
    "    'Group': 'dep',\n",
    "    'Model': 'Huber',\n",
    "    'R^2 test': round(r2_score(y_test_dep, hub_pred_dep_test), 3),\n",
    "    'RMSE test': round(mean_squared_error(y_test_dep, hub_pred_dep_test, squared=False), 3),\n",
    "    'R^2 train': round(r2_score(y_train_dep, hub_pred_dep_train), 3),\n",
    "    'RMSE train': round(mean_squared_error(y_train_dep, hub_pred_dep_train, squared=False), 3)\n",
    "    }, ignore_index=True)\n",
    "\n",
    "eval.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for the best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf_arr = RandomForestRegressor()\n",
    "# Random search of parameters, using 5 fold cross validation, search across 100 different combinations,\n",
    "# and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf_arr, param_distributions=random_grid, n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_arr, y_train_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid to sample from during fitting\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of leafs in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "    }\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for the best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf_arr = RandomForestRegressor()\n",
    "# Random search of parameters, using 5 fold cross validation, search across 100 different combinations,\n",
    "# and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf_arr, param_distributions=random_grid, n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_arr, y_train_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 100,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6c813155746d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Fit the grid search to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/modelengineering/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/modelengineering/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/modelengineering/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    820\u001b[0m                     )\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    823\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/modelengineering/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/modelengineering/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/modelengineering/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/modelengineering/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/modelengineering/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [90, 100, 110],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [1, 2, 4],\n",
    "    'n_estimators': [1300, 1400, 1500]    \n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Initiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=100)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_arr, y_train_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.1, 18.5, 34.9, ..., 51.1, 17.1, 23.8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement second baseline model as random forest regression\n",
    "rand_for_off = RandomForestRegressor(n_estimators = 800, min_samples_split=2, min_samples_leaf=1, max_features='auto', max_depth=100, bootstrap=True, random_state=42)\n",
    "rand_for_off.fit(X_train_dep, y_train_dep)\n",
    "rand_for_off.predict(X_test_dep)\n",
    "\n",
    "rand_for_on = RandomForestRegressor(n_estimators = 10, random_state=42)\n",
    "rand_for_on.fit(X_train_arr, y_train_arr)\n",
    "rand_for_on.predict(X_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r^2 for offblock time is 0.9411\n",
      "The RMSE for offblock time is 6.15minutes.\n",
      "\n",
      "\n",
      "The r^2 for onblock time is 0.963\n",
      "The RMSE for onblock time is 4.64minutes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r2_offarr = rand_for_off.score(X_test_dep, y_test_dep)\n",
    "rmse_offarr = np.sqrt(mean_squared_error(y_test_dep, rand_for_off.predict(X_test_dep)))\n",
    "print('The r^2 for offarr time is ' + str(round(r2_offarr, 4)))\n",
    "print('The RMSE for offarr time is ' + str(round(rmse_offarr, 2)) + 'minutes.')\n",
    "print('\\n')\n",
    "\n",
    "r2_arr = rand_for_on.score(X_test_arr, y_test_arr)\n",
    "rmse_onarr = np.sqrt(mean_squared_error(y_test_arr, rand_for_on.predict(X_test_arr)))\n",
    "print('The r^2 for onarr time is ' + str(round(r2_onarr, 4)))\n",
    "print('The RMSE for onarr time is ' + str(round(rmse_onarr, 2)) + 'minutes.')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.97125,  8.9725 , 26.40625, ..., 46.69125, 10.06875, 18.86125])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement second baseline model as random forest regression\n",
    "rand_for_off = RandomForestRegressor(n_estimators = 800, min_samples_split=2, min_samples_leaf=1, max_features='auto', max_depth=90, bootstrap=True, random_state=42)\n",
    "rand_for_off.fit(X_train_dep, y_train_dep)\n",
    "rand_for_off.predict(X_test_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r^2 for offblock time is 0.9411\n",
      "The RMSE for offblock time is 6.15minutes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r2_offblock = rand_for_off.score(X_test_dep, y_test_dep)\n",
    "rmse_offblock = np.sqrt(mean_squared_error(y_test_dep, rand_for_off.predict(X_test_dep)))\n",
    "print('The r^2 for offblock time is ' + str(round(r2_offblock, 4)))\n",
    "print('The RMSE for offblock time is ' + str(round(rmse_offblock, 2)) + 'minutes.')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence over the day:\n",
    "RMSE in Abhängigkeit der Flüge des Tages\n",
    "RMSE in Abhängigkeit der Uhrzeit\n",
    "\n",
    "\n",
    "PCA\n",
    "Lineare Regression Drop der Variablen"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92e026c127e5e0d2f55e049d7f4aa16d9e4df8376db9ef3d6ecb7a5c71619beb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
